{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fe79ed-0970-4b13-a6ac-4fc4f3c2e628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet\n",
    "import torch._dynamo\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739967f-33c4-46db-9d62-145cb97fabe5",
   "metadata": {},
   "source": [
    "# How to use `torch.compile()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4207f18-e99e-491f-aae3-35696929c824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "input = torch.randn(8, 32)\n",
    "\n",
    "torch._dynamo.reset() # Only needed if you call this cell repeatedly\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "# Alternatively you can also pass the backend\n",
    "compiled_model = torch.compile(model, backend='inductor')\n",
    "\n",
    "output = model(input)\n",
    "# triggers compilation of forward graph on the first run\n",
    "output_compiled = compiled_model(input)\n",
    "\n",
    "torch.all(output == output_compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbc9a7-a4d5-4a12-8384-cdfda6c55ab2",
   "metadata": {},
   "source": [
    "# Benchmark Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbdc444-058e-4439-9ee7-121fd962af1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_batch_inference(model, batch=1):\n",
    "    x = torch.randn(batch, 3, 224, 224).to(device)\n",
    "    model(x)\n",
    "\n",
    "def run_batch_train(model, optimizer, batch=16):\n",
    "    x = torch.randn(batch, 3, 224, 224).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    out.sum().backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "model = resnet.resnet18(weights=resnet.ResNet18_Weights.IMAGENET1K_V1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf99896-0fe4-4b65-a1ed-13296a81c221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f1800eabb80>\n",
      "run_batch_train(model, optimizer, batch)\n",
      "setup: from __main__ import run_batch_train\n",
      "  20.54 ms\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f17b8972e00>\n",
      "run_batch_train(model, optimizer, batch)\n",
      "setup: from __main__ import run_batch_train\n",
      "  19.56 ms\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "\n",
      "Resnet18 Training speedup:  4.78%\n"
     ]
    }
   ],
   "source": [
    "batch = 16\n",
    "torch._dynamo.reset()\n",
    "compiled_model = torch.compile(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "t_model = benchmark.Timer(\n",
    "    stmt='run_batch_train(model, optimizer, batch)',\n",
    "    setup='from __main__ import run_batch_train',\n",
    "    globals={'model': model,'optimizer':optimizer, 'batch':batch})\n",
    "\n",
    "t_compiled_model = benchmark.Timer(\n",
    "    stmt='run_batch_train(model, optimizer, batch)',\n",
    "    setup='from __main__ import run_batch_train',\n",
    "    globals={'model': compiled_model, 'optimizer':optimizer, 'batch':batch})\n",
    "\n",
    "t_model_runs = t_model.timeit(100)\n",
    "t_compiled_model_runs = t_compiled_model.timeit(100)\n",
    "\n",
    "print(t_model_runs)\n",
    "print(t_compiled_model_runs)\n",
    "\n",
    "print(f\"\\nResnet18 Training speedup: {100*(t_model_runs.mean - t_compiled_model_runs.mean) / t_model_runs.mean: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dfab6b2-57da-4bad-a8f1-af5df0c9e49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resnet18 Inference speedup:  31.43%\n"
     ]
    }
   ],
   "source": [
    "batch = 1\n",
    "torch._dynamo.reset()\n",
    "compiled_model = torch.compile(model, mode='reduce-overhead')\n",
    "\n",
    "t_model = benchmark.Timer(\n",
    "    stmt='run_batch_inference(model, batch)',\n",
    "    setup='from __main__ import run_batch_inference',\n",
    "    globals={'model': model, 'batch':batch})\n",
    "\n",
    "t_compiled_model = benchmark.Timer(\n",
    "    stmt='run_batch_inference(model, batch)',\n",
    "    setup='from __main__ import run_batch_inference',\n",
    "    globals={'model': compiled_model, 'batch':batch})\n",
    "\n",
    "t_model_runs = t_model.timeit(100)\n",
    "t_compiled_model_runs = t_compiled_model.timeit(100)\n",
    "\n",
    "print(f\"\\nResnet18 Inference speedup: {100*(t_model_runs.mean - t_compiled_model_runs.mean) / t_model_runs.mean: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4618ba-5d68-4b1a-9fdf-af030aa4b9e0",
   "metadata": {},
   "source": [
    "# Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf10e32d-b29f-4df1-af18-6dadcccc9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "\n",
    "def run_hf_inference(model, input_values):\n",
    "    \n",
    "    # retrieve logits\n",
    "    logits = model(input_values).logits\n",
    "    \n",
    "    # take argmax and decode\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064d2438-2ea2-4d8b-a2ca-97e337b8d8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Found cached dataset librispeech_asr_dummy (/root/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr_dummy/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc)\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "# load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\").cuda()\n",
    "\n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "# tokenize\n",
    "input_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\").input_values.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38053bc2-e349-4899-8efb-ca4c355020c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Huggingface Inference speedup:  4.27%\n"
     ]
    }
   ],
   "source": [
    "batch = 1\n",
    "torch._dynamo.reset()\n",
    "compiled_model = torch.compile(model, mode='max-autotune')\n",
    "\n",
    "t_model = benchmark.Timer(\n",
    "    stmt='run_hf_inference(model, input_values)',\n",
    "    setup='from __main__ import run_hf_inference',\n",
    "    globals={'model': model, 'input_values':input_values})\n",
    "\n",
    "t_compiled_model = benchmark.Timer(\n",
    "    stmt='run_hf_inference(model, input_values)',\n",
    "    setup='from __main__ import run_hf_inference',\n",
    "    globals={'model': compiled_model, 'input_values':input_values})\n",
    "\n",
    "t_model_runs = t_model.timeit(100)\n",
    "t_compiled_model_runs = t_compiled_model.timeit(100)\n",
    "\n",
    "print(f\"\\nHuggingface Inference speedup: {100*(t_model_runs.mean - t_compiled_model_runs.mean) / t_model_runs.mean: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b6c15-7664-4708-ba76-efa33467568f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
